{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "VrpskaJfkhqK"
   },
   "outputs": [],
   "source": [
    "# 1. **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:15.104786Z",
     "iopub.status.busy": "2025-06-22T19:59:15.104610Z",
     "iopub.status.idle": "2025-06-22T19:59:37.862300Z",
     "shell.execute_reply": "2025-06-22T19:59:37.861655Z",
     "shell.execute_reply.started": "2025-06-22T19:59:15.104771Z"
    },
    "id": "dUHDuDdxoD92",
    "outputId": "a9e02881-5496-4b65-c1c4-5c5ed4b5b69c"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pathlib\n",
    "import random\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "#ensure torchinfo is installed\n",
    "\n",
    "try:\n",
    "  import torchinfo\n",
    "except:\n",
    "  !pip install torchinfo\n",
    "  import torchinfo\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "print(f\"torchinfo: {torchinfo.__version__}\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:37.864014Z",
     "iopub.status.busy": "2025-06-22T19:59:37.863525Z",
     "iopub.status.idle": "2025-06-22T19:59:37.949311Z",
     "shell.execute_reply": "2025-06-22T19:59:37.948589Z",
     "shell.execute_reply.started": "2025-06-22T19:59:37.863994Z"
    },
    "id": "Cnm2TKvy3ACJ",
    "outputId": "9dec0a62-4997-4e86-f130-1edd0904bee9"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"The available device is: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "BtvuG-PtM7xA"
   },
   "outputs": [],
   "source": [
    "# **2. Helping Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "_wb9txrgM7xD"
   },
   "outputs": [],
   "source": [
    "## 2.1 Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:37.950772Z",
     "iopub.status.busy": "2025-06-22T19:59:37.950253Z",
     "iopub.status.idle": "2025-06-22T19:59:37.966473Z",
     "shell.execute_reply": "2025-06-22T19:59:37.965836Z",
     "shell.execute_reply.started": "2025-06-22T19:59:37.950742Z"
    },
    "id": "0NLLy9jSM7xE"
   },
   "outputs": [],
   "source": [
    "def train_step(model: nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               device: torch.device,\n",
    "               scaler: GradScaler) -> Tuple[float, float]:\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1. Forward pass with autocast for mixed precision\n",
    "        with autocast():\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 2. Backward pass with scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # 3. Accuracy calculation (outside autocast)\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += ((y_pred_class == y).sum().item() / len(y_pred))\n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "-gFTE0gAM7xI"
   },
   "outputs": [],
   "source": [
    "## 2.2 Validation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:37.968437Z",
     "iopub.status.busy": "2025-06-22T19:59:37.967963Z",
     "iopub.status.idle": "2025-06-22T19:59:37.981326Z",
     "shell.execute_reply": "2025-06-22T19:59:37.980663Z",
     "shell.execute_reply.started": "2025-06-22T19:59:37.968408Z"
    },
    "id": "WgbwQTCVM7xI"
   },
   "outputs": [],
   "source": [
    "def valid_step(model:nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn : torch.nn.Module,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  valid_loss, valid_acc = 0, 0\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      #1. forward pass\n",
    "      valid_pred_logits = model(X)\n",
    "\n",
    "      #2. calculate the loss\n",
    "      loss = loss_fn(valid_pred_logits, y)\n",
    "      valid_loss += loss.item()\n",
    "\n",
    "      #3. calculate accuracy\n",
    "      valid_pred_labels = valid_pred_logits.argmax (dim = 1)\n",
    "      valid_acc += ((valid_pred_labels == y).sum().item()/len(valid_pred_logits))\n",
    "\n",
    "    valid_loss /= len(data_loader)\n",
    "    valid_acc /= len(data_loader)\n",
    "\n",
    "    return valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "js4MU78UM7xJ"
   },
   "outputs": [],
   "source": [
    "## 2.3 Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:37.982622Z",
     "iopub.status.busy": "2025-06-22T19:59:37.982140Z",
     "iopub.status.idle": "2025-06-22T19:59:37.994081Z",
     "shell.execute_reply": "2025-06-22T19:59:37.993306Z",
     "shell.execute_reply.started": "2025-06-22T19:59:37.982603Z"
    },
    "id": "f9z0d5C4M7xK"
   },
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module,\n",
    "                train_dataloader: torch.utils.data.DataLoader,\n",
    "                valid_dataloader: torch.utils.data.DataLoader,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                loss_fn: nn.Module,\n",
    "                epochs: int,\n",
    "                device: torch.device) -> Dict[str, List]:\n",
    "\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"valid_loss\": [],\n",
    "               \"valid_acc\": []}\n",
    "\n",
    "    model.to(device)\n",
    "    scaler = GradScaler()\n",
    "    patience = 0\n",
    "    highest_score = float(\"inf\")\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           data_loader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device,\n",
    "                                           scaler=scaler)\n",
    "\n",
    "        valid_loss, valid_acc = valid_step(model=model,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           device=device,\n",
    "                                           data_loader=valid_dataloader)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if valid_loss < highest_score:\n",
    "            highest_score = valid_loss\n",
    "            patience = 0\n",
    "            best_model_state = model.state_dict()  # Save best model\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 10:\n",
    "                print(f\"Training early-stopped after epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Logging\n",
    "        print(f\"Epoch: {epoch + 1} | \"\n",
    "              f\"train_loss: {train_loss:.3f} | \"\n",
    "              f\"train_acc: {train_acc * 100:.2f}% | \"\n",
    "              f\"valid_loss: {valid_loss:.3f} | \"\n",
    "              f\"valid_acc: {valid_acc * 100:.2f}%\")\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"valid_loss\"].append(valid_loss)\n",
    "        results[\"valid_acc\"].append(valid_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "Axx-acbJM7xL"
   },
   "outputs": [],
   "source": [
    "## 2.4 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:37.994932Z",
     "iopub.status.busy": "2025-06-22T19:59:37.994682Z",
     "iopub.status.idle": "2025-06-22T19:59:38.010435Z",
     "shell.execute_reply": "2025-06-22T19:59:38.009898Z",
     "shell.execute_reply.started": "2025-06-22T19:59:37.994916Z"
    },
    "id": "JVjHwtexM7xM"
   },
   "outputs": [],
   "source": [
    "def pred_and_store(paths: List[pathlib.Path],\n",
    "                   model: torch.nn.Module,\n",
    "                   transform: transforms.Compose,\n",
    "                   class_names: List[str],\n",
    "                   device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")) -> List[Dict]:\n",
    "\n",
    "    # Create an empty list to store prediction dictionaries\n",
    "    pred_list = []\n",
    "\n",
    "    # Loop through the target paths\n",
    "    for path in tqdm(paths):\n",
    "      # Create empty dictionary to store prediction information for each sample\n",
    "      pred_dict = {}\n",
    "      # Get the sample path and ground truth class name\n",
    "      pred_dict[\"image_path\"] = path\n",
    "      class_name = path.parent.stem\n",
    "      pred_dict[\"class_name\"] = class_name\n",
    "\n",
    "      # Start a timer\n",
    "      start_time = timer()\n",
    "\n",
    "      # Open image path and convert to RGB\n",
    "      img = Image.open(path)\n",
    "\n",
    "      # Transform the image, add batch dimension, and send to device\n",
    "      transformed_image = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "      # Prepare model for inference\n",
    "      model.to(device)\n",
    "      model.eval()\n",
    "\n",
    "      # Get prediction\n",
    "      with torch.inference_mode():\n",
    "        pred_logit = model(transformed_image)\n",
    "        try:\n",
    "          pred_logit = pred_logit.logits\n",
    "        except:\n",
    "          pred_logit = pred_logit\n",
    "\n",
    "        pred_prob = torch.softmax(pred_logit, dim=1) #turn logits into prediction probabilities\n",
    "        pred_label = torch.argmax(pred_prob, dim=1) #turn prediction probabilities into prediction label\n",
    "        pred_class = class_names[pred_label.cpu()] #hardcore prediction class on CPU\n",
    "\n",
    "        # Store prediction results\n",
    "        pred_dict[\"pred_prob\"] = round(pred_prob.unsqueeze(0).max().cpu().item(), 4)\n",
    "        pred_dict[\"pred_label\"] = pred_class\n",
    "\n",
    "        # End timer (optional)\n",
    "        end_time = timer()\n",
    "        pred_dict[\"time_per_pred\"] = round(end_time - start_time, 4)\n",
    "\n",
    "      # Match prediction to true label\n",
    "      pred_dict[\"correct\"] = class_name == pred_class\n",
    "\n",
    "      # Append to results list\n",
    "      pred_list.append(pred_dict)\n",
    "\n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "Q1jJLJKmM7xN"
   },
   "outputs": [],
   "source": [
    "## 2.5 Model Evaluation on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:38.012055Z",
     "iopub.status.busy": "2025-06-22T19:59:38.011351Z",
     "iopub.status.idle": "2025-06-22T19:59:38.026030Z",
     "shell.execute_reply": "2025-06-22T19:59:38.025466Z",
     "shell.execute_reply.started": "2025-06-22T19:59:38.012030Z"
    },
    "id": "DiJDRAeiM7xO"
   },
   "outputs": [],
   "source": [
    "def pred_and_plot_image(model:nn.Module,\n",
    "                        image_path: str,\n",
    "                        class_names: List[str],\n",
    "                        image_size: Tuple[int, int] = (224, 224),\n",
    "                        transform: torchvision.transforms = None,\n",
    "                        device: torch.device = device):\n",
    "  img = Image.open(image_path)\n",
    "\n",
    "  if transform is not None:\n",
    "    image_transform = transform\n",
    "\n",
    "  else:\n",
    "    image_transform =  transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #some models may require different sizes\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                        std = [0.229, 0.224, 0.225])\n",
    "])\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    transformed_image = image_transform(img).unsqueeze(dim=0)\n",
    "    target_image_pred = model(transformed_image.to(device))\n",
    "\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim = 1)\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim = 1)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max():.3f}\")\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "RqEYfGeaM7xQ"
   },
   "outputs": [],
   "source": [
    "### 2.5 Calculate Accurcay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:38.026998Z",
     "iopub.status.busy": "2025-06-22T19:59:38.026762Z",
     "iopub.status.idle": "2025-06-22T19:59:38.037341Z",
     "shell.execute_reply": "2025-06-22T19:59:38.036831Z",
     "shell.execute_reply.started": "2025-06-22T19:59:38.026973Z"
    },
    "id": "2enlpDweM7xQ"
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "  correct = torch.eq(y_true, y_pred).sum().item()\n",
    "  acc = (correct/len(y_pred))*100\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "pLXT79hBM7xQ"
   },
   "outputs": [],
   "source": [
    "## 2.6 Model inference on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:38.038380Z",
     "iopub.status.busy": "2025-06-22T19:59:38.038151Z",
     "iopub.status.idle": "2025-06-22T19:59:38.050883Z",
     "shell.execute_reply": "2025-06-22T19:59:38.050383Z",
     "shell.execute_reply.started": "2025-06-22T19:59:38.038358Z"
    },
    "id": "jwuKrLyFM7xR"
   },
   "outputs": [],
   "source": [
    "def get_preds_and_labels(model, dataloader, device):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    y_probs = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            logits = model(X)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            y_pred.extend(preds.cpu().tolist())\n",
    "            y_true.extend(y.cpu().tolist())\n",
    "            y_probs.extend(probs.cpu().tolist())\n",
    "\n",
    "    return y_true, y_pred, y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "irZyvRdEM7xR"
   },
   "outputs": [],
   "source": [
    "## 2.7 Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:38.053885Z",
     "iopub.status.busy": "2025-06-22T19:59:38.053699Z",
     "iopub.status.idle": "2025-06-22T19:59:38.063822Z",
     "shell.execute_reply": "2025-06-22T19:59:38.063228Z",
     "shell.execute_reply.started": "2025-06-22T19:59:38.053871Z"
    },
    "id": "kmtolG0gM7xR"
   },
   "outputs": [],
   "source": [
    "def predict(img) -> Tuple[Dict, float]:\n",
    "  '''Transforms and performs a prediction on img and returns prediction and time taken'''\n",
    "  #start a timer\n",
    "  start_time = timer()\n",
    "\n",
    "  #Transform the target image and add batch dimension\n",
    "  img = auto_transforms(img).unsqueeze(0)\n",
    "\n",
    "  #put model into evaluation mode and turn on inference mode\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    #pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
    "    pred_probs = torch.softmax(model(img), dim=1)\n",
    "\n",
    "  #create a prediction label and prediction probability dictionary\n",
    "  pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
    "\n",
    "  #calculate the prediction time\n",
    "  pred_time = round(timer() - start_time, 5)\n",
    "\n",
    "\n",
    "  return pred_labels_and_probs, pred_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:38.064696Z",
     "iopub.status.busy": "2025-06-22T19:59:38.064508Z",
     "iopub.status.idle": "2025-06-22T19:59:38.075399Z",
     "shell.execute_reply": "2025-06-22T19:59:38.074744Z",
     "shell.execute_reply.started": "2025-06-22T19:59:38.064675Z"
    },
    "id": "RzMFYfV5M7xS"
   },
   "outputs": [],
   "source": [
    "#set hyperparameters\n",
    "EPOCHS = 50\n",
    "FINE_TUNE_EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "num_workers = os.cpu_count()\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:38.076800Z",
     "iopub.status.busy": "2025-06-22T19:59:38.076110Z",
     "iopub.status.idle": "2025-06-22T19:59:38.087062Z",
     "shell.execute_reply": "2025-06-22T19:59:38.086582Z",
     "shell.execute_reply.started": "2025-06-22T19:59:38.076776Z"
    },
    "id": "ulRR7Hz8lNEK"
   },
   "outputs": [],
   "source": [
    "train_dir = \"/kaggle/input/foodvision-101-subset/train\"\n",
    "test_dir = \"/kaggle/input/foodvision-101-subset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "4kCQ9Eep2kgp"
   },
   "outputs": [],
   "source": [
    "# 3. **Download the Pre-Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:38.088073Z",
     "iopub.status.busy": "2025-06-22T19:59:38.087828Z",
     "iopub.status.idle": "2025-06-22T19:59:38.637501Z",
     "shell.execute_reply": "2025-06-22T19:59:38.636894Z",
     "shell.execute_reply.started": "2025-06-22T19:59:38.088045Z"
    },
    "id": "PkNuSWiA2e4V",
    "outputId": "a340a7f2-2fd7-4e5a-e918-320d1d08d13b"
   },
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:38.638419Z",
     "iopub.status.busy": "2025-06-22T19:59:38.638176Z",
     "iopub.status.idle": "2025-06-22T19:59:38.644056Z",
     "shell.execute_reply": "2025-06-22T19:59:38.643405Z",
     "shell.execute_reply.started": "2025-06-22T19:59:38.638392Z"
    },
    "id": "5QGithHW3dSV",
    "outputId": "b9c5b492-f214-4134-cfb4-667a51543b30"
   },
   "outputs": [],
   "source": [
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:38.644883Z",
     "iopub.status.busy": "2025-06-22T19:59:38.644646Z",
     "iopub.status.idle": "2025-06-22T19:59:38.656042Z",
     "shell.execute_reply": "2025-06-22T19:59:38.655365Z",
     "shell.execute_reply.started": "2025-06-22T19:59:38.644868Z"
    },
    "id": "JXf6AkzCM7xY"
   },
   "outputs": [],
   "source": [
    "#trabnsformation for images plotting\n",
    "manual_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "Sa1953WWM7xZ"
   },
   "outputs": [],
   "source": [
    "# 4. **Create Datasets for Data visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:38.656960Z",
     "iopub.status.busy": "2025-06-22T19:59:38.656808Z",
     "iopub.status.idle": "2025-06-22T19:59:47.660368Z",
     "shell.execute_reply": "2025-06-22T19:59:47.659797Z",
     "shell.execute_reply.started": "2025-06-22T19:59:38.656948Z"
    },
    "id": "KttJp7B8M7xc"
   },
   "outputs": [],
   "source": [
    "train_data = ImageFolder(root = train_dir, transform = manual_transform)\n",
    "test_data = ImageFolder(root = test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:47.661294Z",
     "iopub.status.busy": "2025-06-22T19:59:47.661080Z",
     "iopub.status.idle": "2025-06-22T19:59:49.492760Z",
     "shell.execute_reply": "2025-06-22T19:59:49.491969Z",
     "shell.execute_reply.started": "2025-06-22T19:59:47.661270Z"
    },
    "id": "xvHM47TLM7xd",
    "outputId": "1f5cf1a0-5542-4f6a-e138-1095db23fc30"
   },
   "outputs": [],
   "source": [
    "data = {'Subset': ['Train', 'Test'],\n",
    "        'Count': [len(train_data), len(test_data)]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "fig = px.bar(df, x='Subset', y='Count', color='Subset',\n",
    "             color_discrete_sequence=[\"lightgreen\", \"lightblue\"],\n",
    "             text='Count')\n",
    "\n",
    "fig.update_layout(title='Count of images in Train and Test subsets',\n",
    "                  xaxis_title=\"Subset\",\n",
    "                  yaxis_title=\"Count\",\n",
    "                  height=900, width=900)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "OgKNSLbxM7xe"
   },
   "outputs": [],
   "source": [
    "## Dataset Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:49.494158Z",
     "iopub.status.busy": "2025-06-22T19:59:49.493828Z",
     "iopub.status.idle": "2025-06-22T19:59:49.558640Z",
     "shell.execute_reply": "2025-06-22T19:59:49.557576Z",
     "shell.execute_reply.started": "2025-06-22T19:59:49.494130Z"
    },
    "id": "oG9ih5CMM7xe",
    "outputId": "3d121340-3ad4-4c75-f0b3-2a0adb0c74bd"
   },
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "\n",
    "class_counts = Counter(train_data.targets)\n",
    "\n",
    "data_per_class = {'Class': (class_names[i] for i in class_counts.keys()), 'Count': list(class_counts.values())}\n",
    "data_per_class_df = pd.DataFrame(data_per_class)\n",
    "\n",
    "fig = px.bar(data_per_class_df, x='Count', y='Class', text='Count',\n",
    "             color='Class', color_discrete_sequence=px.colors.qualitative.Bold)\n",
    "\n",
    "fig.update_layout(title='Number of Images per Class',\n",
    "                  xaxis_title='Class',\n",
    "                  yaxis_title='Image Count',\n",
    "                  height=900, width=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "1Xqy3CNGM7xf"
   },
   "outputs": [],
   "source": [
    "## Classes Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:49.559930Z",
     "iopub.status.busy": "2025-06-22T19:59:49.559481Z",
     "iopub.status.idle": "2025-06-22T19:59:51.599810Z",
     "shell.execute_reply": "2025-06-22T19:59:51.598801Z",
     "shell.execute_reply.started": "2025-06-22T19:59:49.559901Z"
    },
    "id": "w8Z0nXXLM7xh",
    "outputId": "a8f2e6ae-485d-4ae1-f62c-59226d14d9b6"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "rows, cols = 4,4\n",
    "\n",
    "\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "\n",
    "    img = img.permute(1, 2, 0)\n",
    "\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "jQtDDLgfM7xk"
   },
   "outputs": [],
   "source": [
    "# **4. Data Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:51.601392Z",
     "iopub.status.busy": "2025-06-22T19:59:51.601014Z",
     "iopub.status.idle": "2025-06-22T19:59:54.407427Z",
     "shell.execute_reply": "2025-06-22T19:59:54.406510Z",
     "shell.execute_reply.started": "2025-06-22T19:59:51.601359Z"
    },
    "id": "py1HyTNYM7xr"
   },
   "outputs": [],
   "source": [
    "raw_data = ImageFolder(train_dir)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(raw_data))\n",
    "valid_size = len(raw_data) - train_size\n",
    "train_subset, valid_subset = random_split(raw_data, [train_size, valid_size], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "YCB-UrLPM7xr"
   },
   "outputs": [],
   "source": [
    "# **5. Apply Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:54.409470Z",
     "iopub.status.busy": "2025-06-22T19:59:54.408384Z",
     "iopub.status.idle": "2025-06-22T19:59:54.414380Z",
     "shell.execute_reply": "2025-06-22T19:59:54.413506Z",
     "shell.execute_reply.started": "2025-06-22T19:59:54.409439Z"
    },
    "id": "nDZlCceDM7xs"
   },
   "outputs": [],
   "source": [
    "class TransformSubsets(Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.subset[idx]\n",
    "        return self.transform(img), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:54.415550Z",
     "iopub.status.busy": "2025-06-22T19:59:54.415277Z",
     "iopub.status.idle": "2025-06-22T19:59:54.513716Z",
     "shell.execute_reply": "2025-06-22T19:59:54.512880Z",
     "shell.execute_reply.started": "2025-06-22T19:59:54.415534Z"
    },
    "id": "Z5Kn7DlpM7xs"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_test_transform = transforms.Compose([\n",
    "    transforms.Resize((int(IMG_SIZE * 1.14))),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:54.514833Z",
     "iopub.status.busy": "2025-06-22T19:59:54.514582Z",
     "iopub.status.idle": "2025-06-22T19:59:55.243365Z",
     "shell.execute_reply": "2025-06-22T19:59:55.242594Z",
     "shell.execute_reply.started": "2025-06-22T19:59:54.514802Z"
    },
    "id": "ihHlvu7fM7xs"
   },
   "outputs": [],
   "source": [
    "train_dataset = TransformSubsets(train_subset, train_transform)\n",
    "valid_dataset = TransformSubsets(valid_subset, valid_test_transform)\n",
    "\n",
    "\n",
    "test_dataset = ImageFolder(test_dir, transform=valid_test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "GyId8_igM7xu"
   },
   "outputs": [],
   "source": [
    "# **6. Create Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:55.244477Z",
     "iopub.status.busy": "2025-06-22T19:59:55.244219Z",
     "iopub.status.idle": "2025-06-22T19:59:55.249121Z",
     "shell.execute_reply": "2025-06-22T19:59:55.248401Z",
     "shell.execute_reply.started": "2025-06-22T19:59:55.244459Z"
    },
    "id": "S300eot1M7xu"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:55.250315Z",
     "iopub.status.busy": "2025-06-22T19:59:55.249876Z",
     "iopub.status.idle": "2025-06-22T19:59:56.041888Z",
     "shell.execute_reply": "2025-06-22T19:59:56.041212Z",
     "shell.execute_reply.started": "2025-06-22T19:59:55.250289Z"
    },
    "id": "UesRq7Ki3x-0",
    "outputId": "d831d67c-7961-431e-9143-a5a9883bb044"
   },
   "outputs": [],
   "source": [
    "summary(model = model, input_size = (BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width = 20,\n",
    "        row_settings = [\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "9xVNRDHWM7xw"
   },
   "outputs": [],
   "source": [
    "# 7. **Freeze Feature-Extractor layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:56.042924Z",
     "iopub.status.busy": "2025-06-22T19:59:56.042667Z",
     "iopub.status.idle": "2025-06-22T19:59:56.047295Z",
     "shell.execute_reply": "2025-06-22T19:59:56.046801Z",
     "shell.execute_reply.started": "2025-06-22T19:59:56.042899Z"
    },
    "id": "SGcXKpC95O_u"
   },
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:56.048241Z",
     "iopub.status.busy": "2025-06-22T19:59:56.048037Z",
     "iopub.status.idle": "2025-06-22T19:59:56.061131Z",
     "shell.execute_reply": "2025-06-22T19:59:56.060620Z",
     "shell.execute_reply.started": "2025-06-22T19:59:56.048218Z"
    },
    "id": "75hCaUrn5ro2",
    "outputId": "1282433d-71ae-452c-e179-8498b1f03b84"
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  if param.requires_grad:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "_LzXRwQbM7xx"
   },
   "outputs": [],
   "source": [
    "# 8. **Create the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:56.065866Z",
     "iopub.status.busy": "2025-06-22T19:59:56.065649Z",
     "iopub.status.idle": "2025-06-22T19:59:56.073934Z",
     "shell.execute_reply": "2025-06-22T19:59:56.073368Z",
     "shell.execute_reply.started": "2025-06-22T19:59:56.065843Z"
    },
    "id": "SnWxb-XB5xQP"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "out_shape = len(class_names)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p = 0.2, inplace = True),\n",
    "    nn.Linear(in_features = 1280, out_features = out_shape)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:56.074968Z",
     "iopub.status.busy": "2025-06-22T19:59:56.074694Z",
     "iopub.status.idle": "2025-06-22T19:59:56.190467Z",
     "shell.execute_reply": "2025-06-22T19:59:56.189758Z",
     "shell.execute_reply.started": "2025-06-22T19:59:56.074950Z"
    },
    "id": "H_To5DHA7FzN",
    "outputId": "b418c7f3-81a8-4fd7-8c34-19da36d18143"
   },
   "outputs": [],
   "source": [
    "summary(model = model,\n",
    "        input_size = (32, 3, 224, 224),\n",
    "        verbose=0,\n",
    "        col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width = 20,\n",
    "        row_settings = [\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:56.191519Z",
     "iopub.status.busy": "2025-06-22T19:59:56.191197Z",
     "iopub.status.idle": "2025-06-22T19:59:56.196464Z",
     "shell.execute_reply": "2025-06-22T19:59:56.195748Z",
     "shell.execute_reply.started": "2025-06-22T19:59:56.191491Z"
    },
    "id": "5gZifvdAERGW"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-3, weight_decay = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "C50KYcfJM7xz"
   },
   "outputs": [],
   "source": [
    "# **9. Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "713205c2b91f45c686a76b61d7e8d261"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-06-22T19:59:56.197501Z",
     "iopub.status.busy": "2025-06-22T19:59:56.197183Z",
     "iopub.status.idle": "2025-06-22T20:04:42.256472Z",
     "shell.execute_reply": "2025-06-22T20:04:42.255663Z",
     "shell.execute_reply.started": "2025-06-22T19:59:56.197476Z"
    },
    "id": "lGIth2iyDO1J",
    "outputId": "8842fe7c-fe23-4ee9-de82-20cded632117"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "start_time = timer()\n",
    "epochs = EPOCHS\n",
    "\n",
    "#model=torch.compile(model)\n",
    "\n",
    "results = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=epochs,\n",
    "    device=device)\n",
    "\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time is: {end_time-start_time:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "09VyYj9RM7x2"
   },
   "outputs": [],
   "source": [
    "# **10. Fine-Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:04:42.257885Z",
     "iopub.status.busy": "2025-06-22T20:04:42.257506Z",
     "iopub.status.idle": "2025-06-22T20:04:42.262897Z",
     "shell.execute_reply": "2025-06-22T20:04:42.262248Z",
     "shell.execute_reply.started": "2025-06-22T20:04:42.257854Z"
    },
    "id": "ey4qR0yqM7x5"
   },
   "outputs": [],
   "source": [
    "for param in model.features[-4:].parameters():\n",
    "  param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:04:42.264093Z",
     "iopub.status.busy": "2025-06-22T20:04:42.263835Z",
     "iopub.status.idle": "2025-06-22T20:04:42.277541Z",
     "shell.execute_reply": "2025-06-22T20:04:42.276893Z",
     "shell.execute_reply.started": "2025-06-22T20:04:42.264077Z"
    },
    "id": "tdLyHcdJM7yC"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-5, weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "8245418d7c2c46a5be81761d4f79cb05"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-06-22T20:04:42.278556Z",
     "iopub.status.busy": "2025-06-22T20:04:42.278280Z",
     "iopub.status.idle": "2025-06-22T20:10:35.583165Z",
     "shell.execute_reply": "2025-06-22T20:10:35.582438Z",
     "shell.execute_reply.started": "2025-06-22T20:04:42.278532Z"
    },
    "id": "DM7RU059M7yD",
    "outputId": "87b8e428-a309-430e-9d8f-fc47c5d97868"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "start_time = timer()\n",
    "epochs = FINE_TUNE_EPOCHS\n",
    "\n",
    "#model=torch.compile(model)\n",
    "\n",
    "results = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=epochs,\n",
    "    device=device)\n",
    "\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time is: {end_time-start_time:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "CQLlIM75M7yE"
   },
   "outputs": [],
   "source": [
    "# **11. Save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:10:35.584309Z",
     "iopub.status.busy": "2025-06-22T20:10:35.584072Z",
     "iopub.status.idle": "2025-06-22T20:10:35.643527Z",
     "shell.execute_reply": "2025-06-22T20:10:35.642897Z",
     "shell.execute_reply.started": "2025-06-22T20:10:35.584286Z"
    },
    "id": "5b98ZXHAM7yF",
    "outputId": "36f1073d-c96d-41e4-d60b-05ae44e4cc4e"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/kaggle/working/my_model.pth\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "EiffstGSM7yG"
   },
   "outputs": [],
   "source": [
    "# **12. Model Evaluation on the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:10:35.644465Z",
     "iopub.status.busy": "2025-06-22T20:10:35.644201Z",
     "iopub.status.idle": "2025-06-22T20:10:35.658542Z",
     "shell.execute_reply": "2025-06-22T20:10:35.657899Z",
     "shell.execute_reply.started": "2025-06-22T20:10:35.644447Z"
    },
    "id": "1hjz-t7fM7yH",
    "outputId": "09a0ad2d-a04f-4ad8-d2d3-912e9f02d445"
   },
   "outputs": [],
   "source": [
    "print(f\"[INFO] Finding all filepaths ending with '.jpg' in directory: {test_dir}\")\n",
    "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
    "test_data_paths[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "U-CJmPTuM7yJ"
   },
   "outputs": [],
   "source": [
    "## 12.1 Model predictions ***DataFrame***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "18ddfeac352549eaa99dfc7762eb3f5c"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-06-22T20:10:35.659497Z",
     "iopub.status.busy": "2025-06-22T20:10:35.659214Z",
     "iopub.status.idle": "2025-06-22T20:11:52.037592Z",
     "shell.execute_reply": "2025-06-22T20:11:52.036761Z",
     "shell.execute_reply.started": "2025-06-22T20:10:35.659472Z"
    },
    "id": "9GWezz1wM7yL",
    "outputId": "80ff58db-d494-4fe9-f80c-adb9a71c061d"
   },
   "outputs": [],
   "source": [
    "model_test_pred_dicts = pred_and_store(paths = test_data_paths,\n",
    "                                     model = model,\n",
    "                                     transform = valid_test_transform,\n",
    "                                     class_names = class_names,\n",
    "                                     device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:11:52.038709Z",
     "iopub.status.busy": "2025-06-22T20:11:52.038428Z",
     "iopub.status.idle": "2025-06-22T20:11:52.067522Z",
     "shell.execute_reply": "2025-06-22T20:11:52.066886Z",
     "shell.execute_reply.started": "2025-06-22T20:11:52.038685Z"
    },
    "id": "HfRH3UpZM7yN",
    "outputId": "3e7f489e-55f0-4c1d-c94c-49bad0e99813"
   },
   "outputs": [],
   "source": [
    "model_test_pred_df = pd.DataFrame(model_test_pred_dicts)\n",
    "model_test_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:11:52.068777Z",
     "iopub.status.busy": "2025-06-22T20:11:52.068306Z",
     "iopub.status.idle": "2025-06-22T20:11:52.079347Z",
     "shell.execute_reply": "2025-06-22T20:11:52.078675Z",
     "shell.execute_reply.started": "2025-06-22T20:11:52.068750Z"
    },
    "id": "0_eo2EK-M7yO",
    "outputId": "c987673c-1525-415b-b2bf-e546575a981e"
   },
   "outputs": [],
   "source": [
    "model_test_pred_df.correct.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "jUQUzAW2M7yO"
   },
   "outputs": [],
   "source": [
    "## 12.2 **Model Evaluation with random samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:11:52.080294Z",
     "iopub.status.busy": "2025-06-22T20:11:52.080090Z",
     "iopub.status.idle": "2025-06-22T20:11:52.847170Z",
     "shell.execute_reply": "2025-06-22T20:11:52.846352Z",
     "shell.execute_reply.started": "2025-06-22T20:11:52.080279Z"
    },
    "id": "kC_VPtEeM7yP",
    "outputId": "ad6f780f-3415-4c19-b247-e039d9632df9"
   },
   "outputs": [],
   "source": [
    "num_images_to_plot = 3\n",
    "test_image_path_list = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
    "test_image_path_sample = random.sample(population=test_image_path_list, k=num_images_to_plot)\n",
    "\n",
    "for image_parg in test_image_path_sample:\n",
    "  pred_and_plot_image(model=model,\n",
    "                      image_path=image_parg,\n",
    "                      class_names=class_names,\n",
    "                      image_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:11:52.848299Z",
     "iopub.status.busy": "2025-06-22T20:11:52.848086Z",
     "iopub.status.idle": "2025-06-22T20:11:57.607044Z",
     "shell.execute_reply": "2025-06-22T20:11:57.605961Z",
     "shell.execute_reply.started": "2025-06-22T20:11:52.848282Z"
    },
    "id": "vd0n3sVvM7yP"
   },
   "outputs": [],
   "source": [
    "y_true, y_pred, y_probs = get_preds_and_labels(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "Hb_s60xYM7yQ"
   },
   "outputs": [],
   "source": [
    "## 12.3 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:11:57.608483Z",
     "iopub.status.busy": "2025-06-22T20:11:57.608203Z",
     "iopub.status.idle": "2025-06-22T20:11:57.624167Z",
     "shell.execute_reply": "2025-06-22T20:11:57.623598Z",
     "shell.execute_reply.started": "2025-06-22T20:11:57.608461Z"
    },
    "id": "6T-qyzLHM7yQ",
    "outputId": "78141656-8a95-494a-dd37-bcc0b30b8805"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "knONpPN9M7yR"
   },
   "outputs": [],
   "source": [
    "## 12.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:11:57.625213Z",
     "iopub.status.busy": "2025-06-22T20:11:57.624945Z",
     "iopub.status.idle": "2025-06-22T20:11:57.986357Z",
     "shell.execute_reply": "2025-06-22T20:11:57.985512Z",
     "shell.execute_reply.started": "2025-06-22T20:11:57.625194Z"
    },
    "id": "29jTnNzyM7yR",
    "outputId": "d80dc570-4327-41b1-fc66-3ba407e96655"
   },
   "outputs": [],
   "source": [
    "confusionMatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 8)})\n",
    "ax = sns.heatmap(confusionMatrix, annot=True, cmap='Greens', fmt='g')\n",
    "\n",
    "ax.set_title('Confusion Matrix with Labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Class')\n",
    "ax.set_ylabel('True Class');\n",
    "\n",
    "ax.xaxis.set_ticklabels(class_names)\n",
    "ax.yaxis.set_ticklabels(class_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "YfohI-pZM7yR"
   },
   "outputs": [],
   "source": [
    "# **13. Create a Gradio Demo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:11:57.987631Z",
     "iopub.status.busy": "2025-06-22T20:11:57.987334Z",
     "iopub.status.idle": "2025-06-22T20:12:12.312724Z",
     "shell.execute_reply": "2025-06-22T20:12:12.311891Z",
     "shell.execute_reply.started": "2025-06-22T20:11:57.987608Z"
    },
    "id": "_jChDSsxM7yS",
    "outputId": "651a8cd3-7e13-4a05-dc49-1c73354c5ba1"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import gradio as gr\n",
    "except:\n",
    "  !pip -q install gradio\n",
    "  import gradio as gr\n",
    "\n",
    "print(f\"Gradio version: {gr.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:12.314310Z",
     "iopub.status.busy": "2025-06-22T20:12:12.313659Z",
     "iopub.status.idle": "2025-06-22T20:12:12.365598Z",
     "shell.execute_reply": "2025-06-22T20:12:12.364808Z",
     "shell.execute_reply.started": "2025-06-22T20:12:12.314286Z"
    },
    "id": "Qf05ZzbRM7yT",
    "outputId": "e6ded260-32ec-417d-a56b-0c3c8c2b6516"
   },
   "outputs": [],
   "source": [
    "#create a function to map inputs and outputs\n",
    "model.to(\"cpu\")\n",
    "#check device\n",
    "next(iter(model.parameters())).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:12.367188Z",
     "iopub.status.busy": "2025-06-22T20:12:12.366440Z",
     "iopub.status.idle": "2025-06-22T20:12:12.434229Z",
     "shell.execute_reply": "2025-06-22T20:12:12.433461Z",
     "shell.execute_reply.started": "2025-06-22T20:12:12.367164Z"
    },
    "id": "hncdEBpkM7yT",
    "outputId": "e3e057f9-721b-413c-9180-8ec93491ca35"
   },
   "outputs": [],
   "source": [
    "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
    "\n",
    "#randomly select a test image path\n",
    "random_image_path = random.sample(test_data_paths, k=1)[0]\n",
    "\n",
    "#open the target image\n",
    "image = Image.open(random_image_path)\n",
    "print(f\"[INFO] Predicting on image at path: {random_image_path}\\n\")\n",
    "\n",
    "\n",
    "#predict on the target image and print out the outputs\n",
    "pred_dict, pred_time = predict(img=image)\n",
    "print(f\"Prediction label and probability dictionary: \\n{pred_dict}\")\n",
    "print(f\"prediction time: {pred_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "1TNv4h74M7yU"
   },
   "outputs": [],
   "source": [
    "## 13.1 Create the Demo folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:12.435674Z",
     "iopub.status.busy": "2025-06-22T20:12:12.435402Z",
     "iopub.status.idle": "2025-06-22T20:12:12.441149Z",
     "shell.execute_reply": "2025-06-22T20:12:12.440596Z",
     "shell.execute_reply.started": "2025-06-22T20:12:12.435651Z"
    },
    "id": "EGnMiHsIM7yU",
    "outputId": "f1f0b84a-235c-4f6b-d072-8be1224a4e86"
   },
   "outputs": [],
   "source": [
    "example_list = [[str(filepath)] for filepath in random.sample(test_data_paths, k=10)]\n",
    "example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:12.442581Z",
     "iopub.status.busy": "2025-06-22T20:12:12.442304Z",
     "iopub.status.idle": "2025-06-22T20:12:15.094376Z",
     "shell.execute_reply": "2025-06-22T20:12:15.093763Z",
     "shell.execute_reply.started": "2025-06-22T20:12:12.442554Z"
    },
    "id": "LQ4vdpMOM7yW",
    "outputId": "0e166617-7697-428c-98c5-b2926db3a60c"
   },
   "outputs": [],
   "source": [
    "title = \"FoodVision App\"\n",
    "description = \"An Efficient Computer Vision Model to classify images for Food as Pizza, Steak and Sushi\"\n",
    "article = \"Created at a Pytorch Course\"\n",
    "\n",
    "demo = gr.Interface(fn = predict,\n",
    "                    inputs = gr.Image(type=\"pil\"),\n",
    "                    outputs = [gr.Label(num_top_classes=3, label=\"Predictoins\"),\n",
    "                               gr.Number(label=\"Prediction time (s)\")],\n",
    "                    examples = example_list,\n",
    "                    title=title,\n",
    "                    description=description,\n",
    "                    article=article)\n",
    "\n",
    "demo.launch(debug=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:15.095262Z",
     "iopub.status.busy": "2025-06-22T20:12:15.095078Z",
     "iopub.status.idle": "2025-06-22T20:12:15.269850Z",
     "shell.execute_reply": "2025-06-22T20:12:15.268775Z",
     "shell.execute_reply.started": "2025-06-22T20:12:15.095239Z"
    },
    "id": "F6A38_MKM7ye"
   },
   "outputs": [],
   "source": [
    "foodvision_demo_path = Path(\"demos/foodvision/\")\n",
    "\n",
    "if foodvision_demo_path.exists():\n",
    "  shutil.rmtree(foodvision_demo_path)\n",
    "  foodvision_demo_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "else:\n",
    "  foodvision_demo_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "!ls demos/foodvision/"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "FpvS-3BzM7yf"
   },
   "outputs": [],
   "source": [
    "## 13.2 Create the `Examples folder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:15.271567Z",
     "iopub.status.busy": "2025-06-22T20:12:15.271120Z",
     "iopub.status.idle": "2025-06-22T20:12:15.287053Z",
     "shell.execute_reply": "2025-06-22T20:12:15.286392Z",
     "shell.execute_reply.started": "2025-06-22T20:12:15.271531Z"
    },
    "id": "24ydejjnM7yg",
    "outputId": "364f34ce-18ee-485e-946e-664897965884"
   },
   "outputs": [],
   "source": [
    "foodvision_examples_path = foodvision_demo_path / \"examples\"\n",
    "foodvision_examples_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "foodvision_examples = [Path('/kaggle/input/foodvision-101-subset/test/samosa/2988160.jpg'),\n",
    "                       Path('/kaggle/input/foodvision-101-subset/test/omelette/1243378.jpg'),\n",
    "                       Path('/kaggle/input/foodvision-101-subset/test/steak/3753767.jpg'),\n",
    "                       Path('/kaggle/input/foodvision-101-subset/test/sushi/1987407.jpg'),\n",
    "                       Path('/kaggle/input/foodvision-101-subset/test/sushi/192081.jpg'),\n",
    "                       Path('/kaggle/input/foodvision-101-subset/test/cup_cakes/2939333.jpg'),\n",
    "                       Path('/kaggle/input/foodvision-101-subset/test/french_fries/3310979.jpg'),\n",
    "                       Path('/kaggle/input/foodvision-101-subset/test/steak/1951003.jpg'),\n",
    "                       Path('/kaggle/input/foodvision-101-subset/test/sushi/1383396.jpg'),\n",
    "                       Path('/kaggle/input/foodvision-101-subset/test/steak/3062369.jpg')]\n",
    "\n",
    "for example in foodvision_examples:\n",
    "  destination = foodvision_examples_path / example.name\n",
    "  print(f\"['INFO'] Copying {example} to {destination}\")\n",
    "  shutil.copy2(src=example, dst=destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:15.288250Z",
     "iopub.status.busy": "2025-06-22T20:12:15.287916Z",
     "iopub.status.idle": "2025-06-22T20:12:15.294567Z",
     "shell.execute_reply": "2025-06-22T20:12:15.293813Z",
     "shell.execute_reply.started": "2025-06-22T20:12:15.288223Z"
    },
    "id": "fHgqJsVoM7yg",
    "outputId": "21b6a677-905f-427c-f586-a285d9b89ae9"
   },
   "outputs": [],
   "source": [
    "example_list= [[\"examples/\"+  example] for example in os.listdir(foodvision_examples_path)]\n",
    "example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:15.295508Z",
     "iopub.status.busy": "2025-06-22T20:12:15.295286Z",
     "iopub.status.idle": "2025-06-22T20:12:15.306158Z",
     "shell.execute_reply": "2025-06-22T20:12:15.305392Z",
     "shell.execute_reply.started": "2025-06-22T20:12:15.295487Z"
    },
    "id": "inQHUmYcM7yh",
    "outputId": "c3950326-c3fe-4d09-9192-359c3d4b9b17"
   },
   "outputs": [],
   "source": [
    "model_foodvision_model_path = \"/kaggle/working/my_model.pth\"\n",
    "model_foodvision_model_destination = foodvision_demo_path / Path(model_foodvision_model_path).name\n",
    "\n",
    "\n",
    "try:\n",
    "  print(f\"[INFO] Attempting to move {model_foodvision_model_path} to {model_foodvision_model_destination}\")\n",
    "\n",
    "  shutil.move(src = model_foodvision_model_path,\n",
    "              dst = model_foodvision_model_destination)\n",
    "  print(f\"[INFO] Model move complete\")\n",
    "except:\n",
    "  print(f\"[INFO] No model found at {model_foodvision_model_path}, perhaps it has already been moved\")\n",
    "  print(f\"[INFO] Model exists at {model_foodvision_model_destination} : {model_foodvision_model_destination}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "GV4t2rA6M7yi"
   },
   "outputs": [],
   "source": [
    "## 13.3 Create `Model.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:15.307166Z",
     "iopub.status.busy": "2025-06-22T20:12:15.306960Z",
     "iopub.status.idle": "2025-06-22T20:12:15.318709Z",
     "shell.execute_reply": "2025-06-22T20:12:15.317960Z",
     "shell.execute_reply.started": "2025-06-22T20:12:15.307151Z"
    },
    "id": "QOVbjKMrM7yi",
    "outputId": "747739e3-1ee9-4ca8-e20f-19ffff95377d"
   },
   "outputs": [],
   "source": [
    "%%writefile demos/foodvision/model.py\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def create_model(num_classes: int, seed: int = 42):\n",
    "    # Load pretrained weights and transforms\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "    transforms = weights.transforms()\n",
    "\n",
    "    # Load base model\n",
    "    model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "\n",
    "    # Freeze all base model layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Set random seed\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Update classifier head for your specific number of classes\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1280, out_features=num_classes)\n",
    "    ).to(device)\n",
    "\n",
    "    return model, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "ID9ao7ZBM7yj"
   },
   "outputs": [],
   "source": [
    "## 13.4 Create `app.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:15.319834Z",
     "iopub.status.busy": "2025-06-22T20:12:15.319572Z",
     "iopub.status.idle": "2025-06-22T20:12:15.334121Z",
     "shell.execute_reply": "2025-06-22T20:12:15.333559Z",
     "shell.execute_reply.started": "2025-06-22T20:12:15.319802Z"
    },
    "id": "NkXKnBlJM7yj",
    "outputId": "a00ae1b7-3ea9-4811-9933-fc9cf9653216"
   },
   "outputs": [],
   "source": [
    "%%writefile demos/foodvision/app.py\n",
    "\n",
    "import gradio as gr\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from model import create_model\n",
    "from timeit import default_timer as timer\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"cup_cakes\", \"french_fries\", \"omelette\", \"pizza\", \"samosa\", \"steak\", \"sushi\"]\n",
    "\n",
    "# Load model and transforms\n",
    "model, model_transforms = create_model(num_classes=len(class_names))\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        f=\"my_model.pth\",\n",
    "        map_location=torch.device(\"cpu\")\n",
    "    )\n",
    ")\n",
    "\n",
    "def predict(img) -> Tuple[Dict, float]:\n",
    "    '''Transforms and performs a prediction on img and returns prediction and time taken'''\n",
    "    # Start timer\n",
    "    start_time = timer()\n",
    "\n",
    "    # Transform the image and add batch dimension\n",
    "    img = model_transforms(img).unsqueeze(0)\n",
    "\n",
    "    # Evaluate mode and inference context\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        pred_probs = torch.softmax(model(img), dim=1)\n",
    "\n",
    "    # Prepare predictions\n",
    "    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
    "\n",
    "    # Time taken\n",
    "    pred_time = round(timer() - start_time, 3)\n",
    "\n",
    "    return pred_labels_and_probs, pred_time\n",
    "\n",
    "# Gradio UI setup\n",
    "title = \"FoodVision App\"\n",
    "description = \"An Efficient Computer Vision Model to classify images for 7 types of food\"\n",
    "article = \"Created with Python\"\n",
    "\n",
    "# Load examples\n",
    "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
    "\n",
    "# Interface\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=[\n",
    "        gr.Label(num_top_classes=len(class_names), label=\"Predictions\"),\n",
    "        gr.Number(label=\"Prediction time (s)\")\n",
    "    ],\n",
    "    examples=example_list,\n",
    "    title=title,\n",
    "    description=description,\n",
    "    article=article\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "1C_w5bTjM7yk"
   },
   "outputs": [],
   "source": [
    "## 13.5 Create `Requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:15.335126Z",
     "iopub.status.busy": "2025-06-22T20:12:15.334874Z",
     "iopub.status.idle": "2025-06-22T20:12:15.349963Z",
     "shell.execute_reply": "2025-06-22T20:12:15.349324Z",
     "shell.execute_reply.started": "2025-06-22T20:12:15.335104Z"
    },
    "id": "LTajJ0ybM7yk",
    "outputId": "2842754b-e07e-4a5f-9d98-3ec7d7c0dfca"
   },
   "outputs": [],
   "source": [
    "%%writefile demos/foodvision/requirements.txt\n",
    "torch\n",
    "torchvision\n",
    "gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "7Z1PG5PrM7yl"
   },
   "outputs": [],
   "source": [
    "## 13.6 Zip everything together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:15.351138Z",
     "iopub.status.busy": "2025-06-22T20:12:15.350843Z",
     "iopub.status.idle": "2025-06-22T20:12:16.393757Z",
     "shell.execute_reply": "2025-06-22T20:12:16.393058Z",
     "shell.execute_reply.started": "2025-06-22T20:12:15.351123Z"
    },
    "id": "zQTdfi59M7yl",
    "outputId": "7eaa006f-73b3-462b-81db-4447adf4cb42"
   },
   "outputs": [],
   "source": [
    "!cd demos/foodvision && zip -r ../foodvision.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:12:16.395063Z",
     "iopub.status.busy": "2025-06-22T20:12:16.394769Z",
     "iopub.status.idle": "2025-06-22T20:12:16.566189Z",
     "shell.execute_reply": "2025-06-22T20:12:16.565472Z",
     "shell.execute_reply.started": "2025-06-22T20:12:16.395037Z"
    },
    "id": "22hIA8dMM7yn",
    "outputId": "3b1a0fc9-9f79-4904-e279-6ec252d99980"
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/working/demos/foodvision"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5238938,
     "sourceId": 8728820,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
